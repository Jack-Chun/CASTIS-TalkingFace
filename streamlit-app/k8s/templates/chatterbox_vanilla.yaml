apiVersion: v1
kind: Pod
metadata:
  name: ${POD_NAME}
  labels:
    app: gpu-model-runner
    model: chatterbox
    variant: vanilla
    job-id: ${JOB_ID}
spec:
  restartPolicy: Never
  volumes:
    - name: my-volume
      persistentVolumeClaim:
        claimName: persistent-volume
  terminationGracePeriodSeconds: 1
  containers:
    - name: gpu-worker
      image: ${IMAGE}
      env:
        - name: HOME
          value: /data
        - name: PATH
          value: /data/python/bin:/data/chatterbox-venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: HF_HOME
          value: /data/.cache/huggingface
      command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "=== Chatterbox TTS Generation (VANILLA - No Finetuning) ==="
          echo "Job ID: ${JOB_ID}"
          echo "Text File: ${INPUT_TEXT_FILE}"
          echo "Voice Prompt: ${VOICE_PROMPT}"
          echo "Language: ${LANGUAGE}"
          echo "Output Audio: ${OUTPUT_AUDIO}"
          echo "Started at: $(date)"

          source /data/chatterbox-venv/bin/activate
          cd /data/chatterbox

          # Show GPU info
          echo "=== GPU Info ==="
          nvidia-smi

          # Run inference WITHOUT checkpoint (vanilla model)
          echo "=== Running Chatterbox TTS (Vanilla) ==="
          python inference_tts.py \
            --text-file "${INPUT_TEXT_FILE}" \
            --output "${OUTPUT_AUDIO}" \
            --language "${LANGUAGE}" \
            --voice-prompt "${VOICE_PROMPT}" \
            --exaggeration ${EXAGGERATION} \
            --cfg-weight ${CFG_WEIGHT}

          echo "=== Inference Complete (Vanilla) ==="
          echo "Output saved to: ${OUTPUT_AUDIO}"
          ls -la "${OUTPUT_AUDIO}"
          echo "Finished at: $(date)"
      resources:
        limits:
          nvidia.com/gpu: 1
      volumeMounts:
        - name: my-volume
          mountPath: /data
